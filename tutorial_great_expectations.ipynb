{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations tutorial\n",
    "Welcome! In this tutorial we'll have a look at Great Expectations, a tool written and configured in Python that aids you in keeping an eye on your data quality. It provides a batteries-included solution for testing and documenting your data, so that nobody has to run into any surprises when consuming it. To achieve this, you create _expectation suites_. You can think of them as unit tests, but for data. They also double as documentation for your dataset, so that you won't have to repeat yourself.\n",
    "\n",
    "What do we mean by data quality? Well, bad quality data can happen for different reasons. Usually, data has bad quality if its structure (for example the columns and their types in a table) or its contents (specific cells in a table) are not what you expected.\n",
    "\n",
    "For more background on Great Expectations and the problems it solves, we can recommend the authors' blogpost: [Down with Pipeline debt / Introducing Great Expectations](https://medium.com/@expectgreatdata/down-with-pipeline-debt-introducing-great-expectations-862ddc46782a). It's a good read!\n",
    "\n",
    "## What is Great Expectations (GX) exactly?\n",
    "\n",
    "<img src='figures/in_out.png' width=800px>\n",
    "\n",
    "When working with GX you use the following four core components to access, store, and manage underlying objects and processes:\n",
    "- **Data Context:**  Manages the settings and metadata for a GX project, and provides an entry point to the GX Python API.\n",
    "- **Data Sources:**  Connects to your Data Source, and organizes retrieved data for future use.\n",
    "- **Expectations:**  Identifies the standards to which your data should conform.\n",
    "- **Checkpoints:** Validates a set of Expectations against a specific set of data.\n",
    "\n",
    "\n",
    "## In this tutorial\n",
    "We'll give you a brief introduction to the main concepts used in Great Expectations, walking you through writing your first expectations and generating your first data report. We have added many references to the official documentation that you can reference to when you are configuring your own setup.\n",
    "\n",
    "Contents:\n",
    "- [Data Context](#section-data-context)\n",
    "- [The Expectation Suite](#section-expectation-suite)\n",
    "- [Data Docs](#section-data-docs)\n",
    "- [Checkpoints](#section-checkpoints)\n",
    "- [Data Profiling](#section-profiling)\n",
    "- [The Great Expectations CLI](#section-cli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on Google Colab\n",
    "\n",
    "If you are running this on Google Colab, make sure to run the cell below to set everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [[ ! -d gx ]]\n",
    "then \n",
    "  git init\n",
    "  git remote add origin https://github.com/datarootsio/tutorial-great-expectations.git\n",
    "  git pull origin main\n",
    "  pip install -r requirements.txt\n",
    "  apt-get install tree\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "print(gx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-context\"></a>\n",
    "## Data Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = gx.get_context(project_root_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's take a moment to look at the `DataContext`, which represents your Great Expectations setup. It consists of a directory holding configuration files, named `gx` by default.\n",
    "\n",
    "Note: we are omitting the `uncommitted` directory here. It contains output files (such as rendered data docs), which are not part of the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - -nI\n"
     ]
    }
   ],
   "source": [
    "!tree gx -nI 'uncommitted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main configuration is located in `great_expectations.yml`. We won't go into all the details here, you can refer to the [data context reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/data_context_reference.html) for that. Instead, we'll just introduce some concepts you'll want to be familiar with:\n",
    "\n",
    "- A **data source** is something that can provide data to Great Expectations, such as an SQL database.\n",
    "- A **data asset** is one dataset that lives in a *data source*, such as an SQL table.\n",
    "- **stores** can be used to configure how expectation and validation data will be stored. See [configuring metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you're interested.\n",
    "\n",
    "These are all configured in the `great_expectations.yml` file. We'll have a brief look at its contents now, but don't mind it too much, this is here for illustration purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/data_context_flowchart.png\" width=1500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat gx/great_expectations.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our dataset, `yellow_tripdata_sample_2019-01.csv` and create a Validator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = context.sources.pandas_default.read_csv(\n",
    "    \"https://raw.githubusercontent.com/great-expectations/gx_tutorials/main/data/yellow_tripdata_sample_2019-01.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Data Source` provides a standard API for accessing and interacting with data from a wide variety of source systems. \n",
    "\n",
    "Great Expectations ships with a number of built-in data sources, including:\n",
    "\n",
    "- Pandas\n",
    "- SQL\n",
    "- Spark\n",
    "- CSV\n",
    "- Excel\n",
    "- BigQuery\n",
    "- Snowflake\n",
    "- Redshift\n",
    "- Postgres\n",
    "- MySQL\n",
    "- ...\n",
    "\n",
    "You can also create your own custom data sources.\n",
    "\n",
    "\n",
    "**No matter which Data Source you use, the Data Source's API remains the same.**\n",
    "\n",
    "Let's look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0b13e1429f4995a4dcb1c732b92815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-15 03:36:12</td>\n",
       "      <td>2019-01-15 03:42:19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>230</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-25 18:20:32</td>\n",
       "      <td>2019-01-25 18:26:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-05 06:47:31</td>\n",
       "      <td>2019-01-05 06:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-09 15:08:02</td>\n",
       "      <td>2019-01-09 15:20:17</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-25 18:49:51</td>\n",
       "      <td>2019-01-25 18:56:44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>246</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0          1  2019-01-15 03:36:12  2019-01-15 03:42:19                1   \n",
       "1          1  2019-01-25 18:20:32  2019-01-25 18:26:55                1   \n",
       "2          1  2019-01-05 06:47:31  2019-01-05 06:52:19                1   \n",
       "3          1  2019-01-09 15:08:02  2019-01-09 15:20:17                1   \n",
       "4          1  2019-01-25 18:49:51  2019-01-25 18:56:44                1   \n",
       "\n",
       "   trip_distance  rate_code_id store_and_fwd_flag  pickup_location_id  \\\n",
       "0            1.0             1                  N                 230   \n",
       "1            0.8             1                  N                 112   \n",
       "2            1.1             1                  N                 107   \n",
       "3            2.5             1                  N                 143   \n",
       "4            0.8             1                  N                 246   \n",
       "\n",
       "   dropoff_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                   48             1          6.5    0.5      0.5        1.95   \n",
       "1                  112             1          6.0    1.0      0.5        1.55   \n",
       "2                    4             2          6.0    0.0      0.5        0.00   \n",
       "3                  158             1         11.0    0.0      0.5        3.00   \n",
       "4                   90             1          6.5    1.0      0.5        1.65   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0           0.0                    0.3          9.75                   NaN  \n",
       "1           0.0                    0.3          9.35                   0.0  \n",
       "2           0.0                    0.3          6.80                   NaN  \n",
       "3           0.0                    0.3         14.80                   NaN  \n",
       "4           0.0                    0.3          9.95                   0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the documentation that came with the data:\n",
    " - vendor_id - A code indicating the TPEP provider that provided the record. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.\n",
    " - pickup_datetime - The date and time when the meter was engaged.\n",
    " - dropoff_datetime - The date and time when the meter was disengaged.\n",
    " - passenger_count - The number of passengers in the vehicle. This is a driver-entered value.\n",
    " - trip_distance - The elapsed trip distance in miles reported by the taximeter.\n",
    " - rate_code_id - The final rate code in effect at the end of the trip. 1= Standard rate, 2=JFK, 3=Newark, 4=Nassau or Westchester, 5=Negotiated fare, 6=Group ride\n",
    " - store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka “store and forward,” because the vehicle did not have a connection to the server. Y= store and forward trip, N= not a store and forward trip\n",
    " - pickup_location_id - TLC Taxi Zone in which the taximeter was engaged\n",
    " - dropoff_location_id - TLC Taxi Zone in which the taximeter was disengaged\n",
    " - payment_type - A numeric code signifying how the passenger paid for the trip. 1= Credit card, 2= Cash, 3= No charge, 4= Dispute, 5= Unknown, 6= Voided trip\n",
    " - fare_amount - The time-and-distance fare calculated by the meter.\n",
    " - extra - Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.\n",
    " - mta_tax - $0.50 MTA tax that is automatically triggered based on the metered rate in use.\n",
    " - tip_amount - This field is automatically populated for credit card tips. Cash tips are not included.\n",
    " - tolls_amount - Total amount of all tolls paid in trip.\n",
    " - improvement_surcharge - $0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.\n",
    " - total_amount - The total amount charged to passengers. Does not include cash tips.\n",
    " - congestion_surcharge - $2.50 surcharge for all trips that begin, end or pass through the Manhattan exclusionary zone.\n",
    " \n",
    "These descriptions sure help us to understand the dataset a bit better, but they don't exactly provide much guarantees. When consuming this dataset, what expectations can we have? Will the `passenger_count` field always be specified? Will the `dropoff_datetime` field always be in the same format? Is the total amount always positive?\n",
    "\n",
    "Great Expectations helps us to codify these properties in a set of `Expectations`. An `Expectation` is something that you expect to be true in your data. Again, think of it as an unit test for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `DataContext` ready, we can add `Expectations`. An Expectation is a verifiable assertion about data. Expectations enhance communication about your data and improve quality for data applications. They help you take the implicit assumptions about your data and make them explicit.\n",
    "\n",
    "\n",
    "There are many built-in Expectations, see https://greatexpectations.io/expectations/ for a full list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Expectation uses domain knowledge (the `pickup_datetime` shouldn't be null).\n",
    "\n",
    "The second Expectation uses `auto=True` to detect a range of values in the passenger_count column. This combines Data Profiling with Data Testing, more on Data Profiling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2aab3ed9ce4ca6bd31bb0f77a609d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37503961b8764823b87a5ab00fe04dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Expectations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae00a9bae4406e9b9367bbceaf4f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd1f0d8838e487f885daa2872f3e72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2e3390abaf4766b6766f3dbe82c7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Profiling Dataset:         0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e31f59a7de54a1abc63ee6c8a64ae27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc543c037db4eddac9db4e5b0727767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7653d5dc544947feb887c6125b8d5abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"expectation_config\": {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"min_value\": 1,\n",
       "      \"max_value\": 6,\n",
       "      \"strict_max\": false,\n",
       "      \"mostly\": 1.0,\n",
       "      \"strict_min\": false,\n",
       "      \"column\": \"passenger_count\"\n",
       "    },\n",
       "    \"meta\": {\n",
       "      \"auto_generated_at\": \"20231109T140437.149996Z\",\n",
       "      \"great_expectations_version\": \"0.18.1\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 10000,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"partial_unexpected_list\": [],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_values_to_not_be_null(\"pickup_datetime\")\n",
    "validator.expect_column_values_to_be_between(\"passenger_count\", auto=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our Expectations to a file so we can reuse them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run these Expectations against our data. For this, we'll use a `Checkpoint`. A Checkpoint is a collection of Expectations and a Data Asset. It is a way to package up a test suite and apply it to a data asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=\"checkpoint_1\",\n",
    "    validator=validator,\n",
    ")\n",
    "checkpoint_result = checkpoint.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"run_id\": {\n",
       "    \"run_name\": null,\n",
       "    \"run_time\": \"2023-11-09T15:04:45.485392+01:00\"\n",
       "  },\n",
       "  \"run_results\": {\n",
       "    \"ValidationResultIdentifier::default/__none__/20231109T140445.485392Z/default_pandas_datasource-#ephemeral_pandas_asset\": {\n",
       "      \"validation_result\": {\n",
       "        \"success\": true,\n",
       "        \"results\": [\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"expectation_config\": {\n",
       "              \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"pickup_datetime\",\n",
       "                \"batch_id\": \"default_pandas_datasource-#ephemeral_pandas_asset\"\n",
       "              },\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 10000,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_counts\": [],\n",
       "              \"partial_unexpected_index_list\": []\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_traceback\": null,\n",
       "              \"exception_message\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"expectation_config\": {\n",
       "              \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "              \"kwargs\": {\n",
       "                \"auto\": true,\n",
       "                \"column\": \"passenger_count\",\n",
       "                \"max_value\": 6,\n",
       "                \"min_value\": 1,\n",
       "                \"mostly\": 1.0,\n",
       "                \"strict_max\": false,\n",
       "                \"strict_min\": false,\n",
       "                \"batch_id\": \"default_pandas_datasource-#ephemeral_pandas_asset\"\n",
       "              },\n",
       "              \"meta\": {\n",
       "                \"profiler_config\": {\n",
       "                  \"class_name\": \"BaseRuleBasedProfiler\",\n",
       "                  \"config_version\": 1.0,\n",
       "                  \"module_name\": \"great_expectations.rule_based_profiler.rule_based_profiler\",\n",
       "                  \"name\": \"expect_column_values_to_be_between\",\n",
       "                  \"rules\": [\n",
       "                    {\n",
       "                      \"domain_builder\": {\n",
       "                        \"class_name\": \"ColumnDomainBuilder\",\n",
       "                        \"exclude_column_name_suffixes\": null,\n",
       "                        \"exclude_column_names\": null,\n",
       "                        \"exclude_semantic_types\": null,\n",
       "                        \"include_column_name_suffixes\": null,\n",
       "                        \"include_column_names\": [\n",
       "                          \"passenger_count\"\n",
       "                        ],\n",
       "                        \"include_semantic_types\": null,\n",
       "                        \"module_name\": \"great_expectations.rule_based_profiler.domain_builder.column_domain_builder\",\n",
       "                        \"semantic_type_filter_class_name\": null,\n",
       "                        \"semantic_type_filter_module_name\": null\n",
       "                      },\n",
       "                      \"expectation_configuration_builders\": [\n",
       "                        {\n",
       "                          \"class_name\": \"DefaultExpectationConfigurationBuilder\",\n",
       "                          \"column\": \"$domain.domain_kwargs.column\",\n",
       "                          \"condition\": null,\n",
       "                          \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "                          \"max_value\": \"$parameter.column_max_range_estimator.value[1]\",\n",
       "                          \"meta\": {\n",
       "                            \"profiler_details\": {\n",
       "                              \"column_max_range_estimator\": \"$parameter.column_max_range_estimator.details\",\n",
       "                              \"column_min_range_estimator\": \"$parameter.column_min_range_estimator.details\"\n",
       "                            }\n",
       "                          },\n",
       "                          \"min_value\": \"$parameter.column_min_range_estimator.value[0]\",\n",
       "                          \"module_name\": \"great_expectations.rule_based_profiler.expectation_configuration_builder.default_expectation_configuration_builder\",\n",
       "                          \"mostly\": \"$variables.mostly\",\n",
       "                          \"strict_max\": \"$variables.strict_max\",\n",
       "                          \"strict_min\": \"$variables.strict_min\",\n",
       "                          \"validation_parameter_builder_configs\": [\n",
       "                            {\n",
       "                              \"class_name\": \"NumericMetricRangeMultiBatchParameterBuilder\",\n",
       "                              \"enforce_numeric_metric\": true,\n",
       "                              \"estimator\": \"$variables.estimator\",\n",
       "                              \"evaluation_parameter_builder_configs\": null,\n",
       "                              \"false_positive_rate\": \"$variables.false_positive_rate\",\n",
       "                              \"include_estimator_samples_histogram_in_details\": \"$variables.include_estimator_samples_histogram_in_details\",\n",
       "                              \"metric_domain_kwargs\": \"$domain.domain_kwargs\",\n",
       "                              \"metric_multi_batch_parameter_builder_name\": null,\n",
       "                              \"metric_name\": \"column.min\",\n",
       "                              \"metric_value_kwargs\": null,\n",
       "                              \"module_name\": \"great_expectations.rule_based_profiler.parameter_builder\",\n",
       "                              \"n_resamples\": \"$variables.n_resamples\",\n",
       "                              \"name\": \"column_min_range_estimator\",\n",
       "                              \"quantile_bias_correction\": \"$variables.quantile_bias_correction\",\n",
       "                              \"quantile_bias_std_error_ratio_threshold\": \"$variables.quantile_bias_std_error_ratio_threshold\",\n",
       "                              \"quantile_statistic_interpolation_method\": \"$variables.quantile_statistic_interpolation_method\",\n",
       "                              \"random_seed\": \"$variables.random_seed\",\n",
       "                              \"reduce_scalar_metric\": true,\n",
       "                              \"replace_nan_with_zero\": true,\n",
       "                              \"round_decimals\": \"$variables.round_decimals\",\n",
       "                              \"truncate_values\": \"$variables.truncate_values\"\n",
       "                            },\n",
       "                            {\n",
       "                              \"class_name\": \"NumericMetricRangeMultiBatchParameterBuilder\",\n",
       "                              \"enforce_numeric_metric\": true,\n",
       "                              \"estimator\": \"$variables.estimator\",\n",
       "                              \"evaluation_parameter_builder_configs\": null,\n",
       "                              \"false_positive_rate\": \"$variables.false_positive_rate\",\n",
       "                              \"include_estimator_samples_histogram_in_details\": \"$variables.include_estimator_samples_histogram_in_details\",\n",
       "                              \"metric_domain_kwargs\": \"$domain.domain_kwargs\",\n",
       "                              \"metric_multi_batch_parameter_builder_name\": null,\n",
       "                              \"metric_name\": \"column.max\",\n",
       "                              \"metric_value_kwargs\": null,\n",
       "                              \"module_name\": \"great_expectations.rule_based_profiler.parameter_builder\",\n",
       "                              \"n_resamples\": \"$variables.n_resamples\",\n",
       "                              \"name\": \"column_max_range_estimator\",\n",
       "                              \"quantile_bias_correction\": \"$variables.quantile_bias_correction\",\n",
       "                              \"quantile_bias_std_error_ratio_threshold\": \"$variables.quantile_bias_std_error_ratio_threshold\",\n",
       "                              \"quantile_statistic_interpolation_method\": \"$variables.quantile_statistic_interpolation_method\",\n",
       "                              \"random_seed\": \"$variables.random_seed\",\n",
       "                              \"reduce_scalar_metric\": true,\n",
       "                              \"replace_nan_with_zero\": true,\n",
       "                              \"round_decimals\": \"$variables.round_decimals\",\n",
       "                              \"truncate_values\": \"$variables.truncate_values\"\n",
       "                            }\n",
       "                          ]\n",
       "                        }\n",
       "                      ],\n",
       "                      \"parameter_builders\": [],\n",
       "                      \"variables\": {\n",
       "                        \"estimator\": \"exact\",\n",
       "                        \"include_estimator_samples_histogram_in_details\": false,\n",
       "                        \"mostly\": 1.0,\n",
       "                        \"round_decimals\": null,\n",
       "                        \"strict_max\": false,\n",
       "                        \"strict_min\": false,\n",
       "                        \"truncate_values\": {\n",
       "                          \"lower_bound\": null,\n",
       "                          \"upper_bound\": null\n",
       "                        }\n",
       "                      }\n",
       "                    }\n",
       "                  ],\n",
       "                  \"variables\": {}\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 10000,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_percent_total\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_counts\": [],\n",
       "              \"partial_unexpected_index_list\": []\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_traceback\": null,\n",
       "              \"exception_message\": null\n",
       "            }\n",
       "          }\n",
       "        ],\n",
       "        \"evaluation_parameters\": {},\n",
       "        \"statistics\": {\n",
       "          \"evaluated_expectations\": 2,\n",
       "          \"successful_expectations\": 2,\n",
       "          \"unsuccessful_expectations\": 0,\n",
       "          \"success_percent\": 100.0\n",
       "        },\n",
       "        \"meta\": {\n",
       "          \"great_expectations_version\": \"0.18.1\",\n",
       "          \"expectation_suite_name\": \"default\",\n",
       "          \"run_id\": {\n",
       "            \"run_name\": null,\n",
       "            \"run_time\": \"2023-11-09T15:04:45.485392+01:00\"\n",
       "          },\n",
       "          \"batch_spec\": {\n",
       "            \"reader_method\": \"read_csv\",\n",
       "            \"reader_options\": {\n",
       "              \"filepath_or_buffer\": \"https://raw.githubusercontent.com/great-expectations/gx_tutorials/main/data/yellow_tripdata_sample_2019-01.csv\"\n",
       "            }\n",
       "          },\n",
       "          \"batch_markers\": {\n",
       "            \"ge_load_time\": \"20231109T140445.494484Z\",\n",
       "            \"pandas_data_fingerprint\": \"c4f929e6d4fab001fedc9e075bf4b612\"\n",
       "          },\n",
       "          \"active_batch_definition\": {\n",
       "            \"datasource_name\": \"default_pandas_datasource\",\n",
       "            \"data_connector_name\": \"fluent\",\n",
       "            \"data_asset_name\": \"#ephemeral_pandas_asset\",\n",
       "            \"batch_identifiers\": {}\n",
       "          },\n",
       "          \"validation_time\": \"20231109T140445.688532Z\",\n",
       "          \"checkpoint_name\": \"checkpoint_1\",\n",
       "          \"validation_id\": null,\n",
       "          \"checkpoint_id\": null\n",
       "        }\n",
       "      },\n",
       "      \"actions_results\": {\n",
       "        \"store_validation_result\": {\n",
       "          \"class\": \"StoreValidationResultAction\"\n",
       "        },\n",
       "        \"store_evaluation_params\": {\n",
       "          \"class\": \"StoreEvaluationParametersAction\"\n",
       "        },\n",
       "        \"update_data_docs\": {\n",
       "          \"local_site\": \"file://c:\\\\Users\\\\robin\\\\projects\\\\tutorial-great-expectations\\\\gx\\\\uncommitted/data_docs/local_site/validations%5Cdefault%5C__none__%5C20231109T140445.485392Z%5Cdefault_pandas_datasource-%23ephemeral_pandas_asset.html\",\n",
       "          \"class\": \"UpdateDataDocsAction\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"checkpoint_config\": {\n",
       "    \"default_validation_id\": null,\n",
       "    \"notify_with\": null,\n",
       "    \"batch_request\": {},\n",
       "    \"validations\": [\n",
       "      {\n",
       "        \"expectation_suite_name\": \"default\",\n",
       "        \"expectation_suite_ge_cloud_id\": null,\n",
       "        \"name\": null,\n",
       "        \"batch_request\": {\n",
       "          \"datasource_name\": \"default_pandas_datasource\",\n",
       "          \"data_asset_name\": \"#ephemeral_pandas_asset\",\n",
       "          \"options\": {},\n",
       "          \"batch_slice\": null\n",
       "        },\n",
       "        \"id\": null\n",
       "      }\n",
       "    ],\n",
       "    \"evaluation_parameters\": {},\n",
       "    \"expectation_suite_ge_cloud_id\": null,\n",
       "    \"name\": \"checkpoint_1\",\n",
       "    \"module_name\": \"great_expectations.checkpoint\",\n",
       "    \"expectation_suite_name\": null,\n",
       "    \"profilers\": [],\n",
       "    \"runtime_configuration\": {},\n",
       "    \"config_version\": 1.0,\n",
       "    \"site_names\": null,\n",
       "    \"slack_webhook\": null,\n",
       "    \"notify_on\": null,\n",
       "    \"class_name\": \"Checkpoint\",\n",
       "    \"action_list\": [\n",
       "      {\n",
       "        \"name\": \"store_validation_result\",\n",
       "        \"action\": {\n",
       "          \"class_name\": \"StoreValidationResultAction\"\n",
       "        }\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"store_evaluation_params\",\n",
       "        \"action\": {\n",
       "          \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "        }\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"update_data_docs\",\n",
       "        \"action\": {\n",
       "          \"class_name\": \"UpdateDataDocsAction\"\n",
       "        }\n",
       "      }\n",
       "    ],\n",
       "    \"ge_cloud_id\": null,\n",
       "    \"template_name\": null,\n",
       "    \"run_name_template\": null\n",
       "  },\n",
       "  \"success\": true\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint runs are the primary way to use Great Expectations in automated workflows. They are designed to be used in automated data quality pipelines, and can be run from the command line, from notebooks, or from any other Python code. They produce a JSON-formatted validation result document that can be used for further analysis or as a report. Data Docs are also updated with the results of Checkpoint runs and can be used to monitor data quality over time. Data Docs are saved as static HTML files and can be easily shared with others and viewed in any web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we covered the basics, let's get to some fancier expectations. For example, we could make sure that all date columns are in the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c95779ff924a80afb3adb45d5548aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b292b591db554571a40be6810b0254be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 10000,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"partial_unexpected_list\": [],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_values_to_match_strftime_format('pickup_datetime', \"%Y-%m-%d %H:%M:%S\")\n",
    "validator.expect_column_values_to_match_strftime_format('dropoff_datetime', \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bee68778bc842b69ee0c7e838bbd59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validator.save_expectation_suite()\n",
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=\"checkpoint_2\",\n",
    "    validator=validator,\n",
    ")\n",
    "\n",
    "checkpoint_result = checkpoint.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the expectations we've implemented so far have been met by our data. But what happens if we run into a problem? Let's try it out by adding a new expectation that checks if the `vendor_id` is always 1 or 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacdc684affa48dcbe9d7467dde63498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"result\": {\n",
       "    \"element_count\": 10000,\n",
       "    \"unexpected_count\": 96,\n",
       "    \"unexpected_percent\": 0.96,\n",
       "    \"partial_unexpected_list\": [\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4,\n",
       "      4\n",
       "    ],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.96,\n",
       "    \"unexpected_percent_nonmissing\": 0.96\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_values_to_be_in_set('vendor_id', [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That failed. Great Expectations helpfully collected the values which do not match the expectation for us. By default, it will collect up to 20 examples of values that didn't meet the expectation (that's why it's called the _partial_ unexpected list). \n",
    "\n",
    "In the Data Docs, you can see that the expectation failed, and you can also see the unexpected values. This is very useful when you are trying to debug your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60f59a629794b0d8373dba305b89159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=\"checkpoint_3\",\n",
    "    validator=validator,\n",
    ")\n",
    "\n",
    "checkpoint_result = checkpoint.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check out the [glossary of expectations](https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html) for a complete list of what you can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-expectation-suite\"></a>\n",
    "## The Expectation Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we were experimenting up there, great_expectations remembered all the expectations we ran. We can now retrieve the suite contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us the `dict` representation Great Expectations uses under the hood to keep track of our exepectation suite. Can you recognise some of the expectations we wrote?\n",
    "\n",
    "An expectation suite is just a sequence of expectations, as shown below.\n",
    "<img src=\"figures/expectation_suite.png\">\n",
    "This representation can then be saved to a file, so that we can load it again at another time, without depending on the python code that produced it.\n",
    "\n",
    "Note that by default, expectations that failed on the `batch` we ran them against will be omitted. If you want to include them anyways, you could add the `discard_failed_expectations=False` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that command do? Let's open up our configuration folder to try and find our expectation suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tree great_expectations -nI \"uncommitted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get back to the configuration in a minute [[Data Context]](#section-data-context), so don't get confused about this yet.\n",
    "\n",
    "As you can see, the `save_expectation_suite` command saved our `check_avocado_data` suite to the `expectations` folder. That's all there is to it, the expectation suite is just a json file. It contains that same internal representation that we retrieved from `get_expectation_suite()`. You can check it out if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat great_expectations/expectations/check_avocado_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectations are stored in the *expectation store*, which by default is the `expectations` folder inside your configuration, but you can use other storage backends as well, such as a SQL database or cloud storage (S3, Azure Blob Storage or GCS). See [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validation-results\"></a>\n",
    "Now that we added our expectation suite to our `DataContext`, we can try running the entire suite.\n",
    "Validiating your data against an expectation suite is done by running a **validation operator**. A validation operator describes what should be done with your validation results. Here, we would like to store the results on disk, and generate a friendly report on them. We'll show you how this is configured in the [Data Context section](#section-data-context), in the meanwhile we'll use `my_validation_operator`, which we shipped with the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = context.run_validation_operator('my_validation_operator', assets_to_validate=[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One validation run can include multiple batches and expectation suites. This way, it is possible to test multiple files in the same run. Compare this to how one run of your test suite can test multiple software modules.\n",
    "\n",
    "We didn't explicitly specify the expectation suite to use with our data batch, because `batch` keeps track of the expectation suite for us. We already saw this when we retrieved the suite from it at the beginning of this section.\n",
    "\n",
    "Now that we got through that, let's have a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *validation result*. Validation results are kept in the *validation store*, which is the `great_expectations/uncommitted/validations` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -n great_expectations/uncommitted/validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great Expectations also allows you to set other backends as a validation store, such as your favourite cloud storage offering, or a SQL database. Check out [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you would like to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-docs\"></a>\n",
    "## Data Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render these results to a friendly report, called a data doc. These data docs will describe the expectations that the data should meet, as well as the metrics detailing how well the data meets the requirements. This is how Great Expectations combines testing with documenting.\n",
    "\n",
    "Remember that we already built the data docs using `my_validation_operator` in the previous section. Let's check them out now! We'll take you to the index page, make sure to browse around for a bit. In the `Validation Results` tab you'll find the validation run we ran above. Click it for a friendly report on its results. In the `Expectation Suites` tab, you can find a document detailing the expectations set by our `check_avocado_data` suite. You'll see the expectations we ran above reflected in the different sections.\n",
    "\n",
    "If you are running the tutorial on your OS, run this command to open the data docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running on docker, try this link [here](/view/great_expectations/uncommitted/data_docs/local_site/index.html). If the links don't work in your browser, you could try using the [jupyter file browser](/tree/great_expectations/uncommitted/data_docs/local_site). It's not ideal, but it works. \n",
    "\n",
    "Otherwise, you can view the results for our run [here](https://datarootsio.github.io/tutorial-great-expectations/validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for validation results, different storage backends can be configured for your data docs. You could, for example, host them on cloud storage for easy viewing. Refer to [configuring data docs](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_data_docs.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-checkpoints\"></a>\n",
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we launched a validation run back in the [Expectation Suite section](#section-expectation-suite). There, we wrote code to run the validation on the data batch and expectation suite that we defined earlier on. If we bundle all these run parameters in a single configuration file, we could easily rerun the validation, for example each time our data changes. Such a configuration file is called a `Checkpoint` in Great Expectations.\n",
    "\n",
    "As a quick reminder, for running a validation we need:\n",
    "- A *validation operator* to handle the validation results\n",
    "- A list of *batches*, each consisting of\n",
    "    - A batch of data to check\n",
    "    - expectation suites to check against\n",
    "    \n",
    "To create a checkpoint, we simply create a file in the `checkpoints` directory of our great_expectations configuration. We'll create the file manually now for demonstration purposes, but when doing this in your own project you probably want to use the CLI [[The Great Expectations CLI]](#section-cli), which will help you along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile great_expectations/checkpoints/avocado_data.yml\n",
    "\n",
    "validation_operator_name: my_validation_operator\n",
    "batches:\n",
    "  - batch_kwargs:\n",
    "      path: data/avocado.csv\n",
    "      datasource: data_dir\n",
    "      data_asset_name: avocado\n",
    "      reader_method: read_csv\n",
    "      reader_options:\n",
    "        index_col: 0\n",
    "    expectation_suite_names:\n",
    "      - check_avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `batch_kwargs` property specifies how the data asset should be loaded. You might recognise the parameters from when we first loaded the `avocado.csv` file.\n",
    "\n",
    "This might also be a good time to point out that our data batch will get read by pandas under the hood (we configured that in the `data_dir` data source). In `batch_kwargs`, we specify that we'd like to use the pandas `read_csv` method, which will receive the `reader_options` dict as additional parameters.\n",
    "For more information on batches, check out the [creating batches](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/creating_batches.html) guide.\n",
    "\n",
    "The checkpoint can be executed by using the great_expectations cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!great_expectations checkpoint run avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to summarize: a checkpoint is a _runnable check_ for your data. They are your first stop for integrating Great Expectations into your pipelines and workflows.\n",
    "For more info on how to do that, refer to the [validation guides](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation.html), or the [workflows and patterns](https://docs.greatexpectations.io/en/latest/guides/workflows_patterns.html) guides.\n",
    "\n",
    "Checkpoints and batches are represented visually below.\n",
    "\n",
    "<img src=\"figures/checkpoint.png\" width=600px>\n",
    "<img src=\"figures/batch.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-profiling\"></a>\n",
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we explored how we could get some metrics about our data using expectations. But what if you don't know what exactly to expect of your data? Well, you could try using Great Expectations' profiling feature, which can try to extract some useful metrics from your data. To try profiling our preconfigured `data_dir` data source, we can use the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!great_expectations datasource profile data_dir -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running on your own OS, running that command should have opened the freshly built data docs in your browser. If not, you can view the [results from our run](https://datarootsio.github.io/tutorial-great-expectations/profiling). You can find the results in the `Profiling Results` tab. The profiler also generated an expectation suite based on its observations, which you can find in the `Expectation Suites` tab. Be mindful that this is an experimental feature and the generated suite is usually not that helpful, but it could be a good starting point for writing your own.\n",
    "\n",
    "\n",
    "If you'd like to know more about profiling, the [profiling reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/profiling_reference.html) can help you out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-cli\"></a>\n",
    "## The Great Expectations CLI\n",
    "\n",
    "For the purposes of this tutorial, we mostly interacted directly with Great Expectations. If you are going to set up and use Great Expectations for yourself, we recommend using the CLI as much as possible. The concepts should be familiar by now - refer to the  [CLI guide](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/miscellaneous/command_line.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!great_expectations --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-setup\"></a>\n",
    "## Setting up your own project\n",
    "\n",
    "To initialize your own project, run `great_expectations init` and follow the instructions. This will scaffold a simple configuration for you, just like the one we provided.\n",
    "\n",
    "Once you created your suite using `great_expectations suite new`, you can use the `great_expectations suite edit` command to open up an auto-generated notebook that you can use to set up your suite. You should be able to recognise the structure of the first part of this notebook a bit ;-)\n",
    "\n",
    "The [getting started guide](https://docs.greatexpectations.io/en/latest/guides/tutorials/getting_started.html) can  help you along the way. For ideas on how Great Expectation can fit into your workflow, check out [Deployment patterns](https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation.html#deployment-patterns).\n",
    "\n",
    "<a id=\"section-conclusion\"></a>\n",
    "## Final words\n",
    "\n",
    "Just to recap, in this tutorial notebook, we started by giving you an overview of the tool and its purpose. We then showed you how to get started with the Python library and define your expectations. We saw that expectations can be bundled as suites, which can be used with validation operators to produce validation results. We had a look at data docs, a clean way to visualize your results and data documentation. We then dived into the data context, showing how the tool is configured. We had a look at checkpoints, which allow you to automate your data testing. We talked a bit about profiling, an experimental feature to generate expectations from given data. Finally, we introduced you to the CLI and set you on the right path to start using Great Expectations right away!\n",
    "\n",
    "We hope you enjoyed the tutorial and wish you all the best in using Great Expectations with your projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
